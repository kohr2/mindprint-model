# Training Pipeline Configuration
# Bob Loukas Mindprint - Mac Studio M2 Ultra (64GB)
# ORPO (Odds Ratio Preference Optimization) training

# Backend configuration (optional - defaults to legacy mode if not specified)
backend:
  type: mlx  # "pytorch" or "mlx" (set to null for legacy mode)
  device: auto  # "auto", "mps", "cuda", "cpu", "gpu"
  dtype: float16  # "float16", "float32", "bfloat16"

# Model (used for legacy mode or backend initialization)
model:
  name: Qwen/Qwen2.5-7B-Instruct
  dtype: float16
  device: mps

# ORPO settings - Odds Ratio Preference Optimization
# ORPO combines supervised fine-tuning and preference alignment in a single stage
orpo:
  steps_per_topic: 100
  learning_rate: 0.0003  # 3e-4
  batch_size: 4
  lambda_orpo: 0.1  # Weight for preference term
  lora_rank: 8
  lora_alpha: 16
  target_modules:
    - q_proj
    - v_proj
    - o_proj
    - up_proj
    - down_proj

# Thresholds
thresholds:
  accuracy_threshold: 0.70  # Min accuracy to pass
  topic_pass_threshold: 0.90  # Combined score (accuracy + voice) / 2 to pass topic

# Pipeline control
pipeline:
  merge_after_unit: true
  max_retries_per_topic: 2

# Paths - Using transcripts dataset
paths:
  data_dir: ./data/bob_loukas/transcripts
  output_dir: ./output
  checkpoint_dir: ./checkpoints

# Logging
logging:
  level: INFO
  log_file: ./logs/training.log
