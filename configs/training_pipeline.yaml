# Training Pipeline Configuration
# Bob Loukas Mindprint - Mac Studio M2 Ultra (64GB)
# Combined SFT + DPO training with evaluation

# Backend configuration (optional - defaults to legacy mode if not specified)
backend:
  type: mlx  # "pytorch" or "mlx" (set to null for legacy mode)
  device: auto  # "auto", "mps", "cuda", "cpu", "gpu"
  dtype: float16  # "float16", "float32", "bfloat16"

# Model (used for legacy mode or backend initialization)
model:
  name: Qwen/Qwen2.5-7B-Instruct
  dtype: float16
  device: mps

# SFT settings
sft:
  epochs_per_topic: 3
  learning_rate: 0.0003  # 3e-4
  batch_size: 4
  lora_rank: 8
  lora_alpha: 16
  target_modules:
    - q_proj
    - v_proj
    - o_proj

# DPO settings
dpo:
  steps_per_topic: 100
  learning_rate: 0.0000005  # 5e-7
  batch_size: 2
  beta: 0.1
  lora_rank: 1
  lora_alpha: 1.0
  target_modules:
    - o_proj
    - v_proj
    - up_proj
    - down_proj

# Thresholds
thresholds:
  accuracy_threshold: 999.0  # DISABLED: Skip DPO to test SFT-only on MPS
  dpo_trigger_threshold: 999.0  # DISABLED: Skip DPO to test SFT-only on MPS
  topic_pass_threshold: 0.70  # Lowered to accept SFT-only results

# Pipeline control
pipeline:
  merge_after_unit: true
  max_retries_per_topic: 2

# Paths
paths:
  data_dir: ./data/bob_loukas
  output_dir: ./output
  checkpoint_dir: ./checkpoints

# Logging
logging:
  level: INFO
  log_file: ./logs/training.log
